# Solutions

This is a working doc identifying the approach this this problem.

This is used by Mitch to map out his task ahead, it won't be the final doc for explain my solution.

## Breakdown

Build a server that:

- `/import`: Receives the XML request and stores it persistently.
- `/results/:test-id/aggregate`: Returns a JSON for
  -  `mean` - the mean of the awarded marks
  -  `count` - the number of students who took the test
  -  `p25`, `p50`, `p75` - the 25th percentile, median, and 75th percentile scores

### Brief requirements and assumptions
- `<summary-marks>` is what we are told to use
  - I find this untrustworthy. I still think we should store the individual answers as a JSON blob.
  - Considered calculating it anyway and storing it, but the historic context of each answer could provide more analytics in the future
- Extra fields to be ignored
  - If we leave things out now, we can't go back in time to get them.
  - Lets store everything for now in JSON even if we don't know what to do with that data yet.
- Other xml files may hit our server
  - `<mcq-test-results>` is a good thing to check against and validate. Full schema validation actually
  - `text/xml+markr` will also be an extra validation
  - Perhaps converting xml to javascript object, then using zod to validate?
- SSL "won't be here when we're hacked"
  - Irresponsible response. Luckily for now this is a local machine. 
  - When we push to prod, the assumption is the server will be behind a load balancer/ingress that handles TLS in production.
- Devops not responding.
  - I don't want to lock us into some obscure DB solution of flashy tech, or over engineer
  - Postgres is boring, but perfect for this use case. Can be used on most IaaS. Super widely supported
  - We need to keep migration history for this reason, and any "hardcoded" or cross env values should be seeded.
- AWS bills
  - Storing additional JSON may increase billing. Need to consider the storage impacts
  - Could potentially use a cheaper, static storage to save money which can be extracted out into the DB if we ever need
- Mean and percentile
  - How to calculate demonitoator for percentage?

#### Aggregate

For a given test-id, compute:
  -	count
  -	mean
  -	p25 / p50 / p75
(all as percentages of available marks)

Concerns:
  - Data arrives incrementally
  - Submissions may be duplicated
  - Available marks may change (take max)
  - Aggregate does not need to be fast right now
  - But might need to be real-time later

Approach:
- Query all relevant rows
- Compute the stats in TS
- Return the result
- If no matching testId, throw error
- If no test submissions, return empty analytics (request was successful just nothing to show yet)

Concerns:
  - O(n) per request
  - Won't scale with lots of data or high requests

## Tech

### Database
postgres

- Atomicity, consistency, isolation and durability (ACID)
- JSON storage for the extra fields we currently don't care about
  - Analytics friendly for querying those fields
- Strong constraints
- Well supported and not locked in to a framework or cloud provider

**Structure**
- Tables
	- student
  	- id
  	- student_number (Assumed to be unique)
  	- first_name
  	- last_name
  - test
    - id (unique, auto generated by our system)
    - test_id (Assumed to be unique)
  - submission
    - id
    - student_id
    - test_id
    - obtained
    - available
    - scanned_on
    - raw_payload
    - updated_at

### Repo
turborepo monorepo

- Allows us to split up the server from the DB code
- Fast and cached
- Separation of concerns with packages, easy to disconnect later
- Awesome docker caching ability

### Server
express

- typescript, so well typed and AI friendly
- Extremely well documented and highly supported.
- Well abstracted, allowing us to focus on logic rather than framework behaviour

### ORM
prisma

- Works fantastically with postgres
- Built in migration and seed support
- Fully generated types based on DB model

### Devtools

Being that this is a ts monorepo, it means we can build in typescript